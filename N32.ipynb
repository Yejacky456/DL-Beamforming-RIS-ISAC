{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "M = 8  \n",
    "N = 32 \n",
    "lr = 0.001\n",
    "\n",
    "sigma2 = 1e-2\n",
    "PdB = 8\n",
    "P = 10**(PdB/10)\n",
    "\n",
    "TaudB = 10\n",
    "Tau = 10**(TaudB/10)\n",
    "\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChannelFile = r'Train_Channel_N_32.mat'\n",
    "chan_theta_mat = scio.loadmat(ChannelFile)\n",
    "\n",
    "G0 = chan_theta_mat['G_all']\n",
    "hrc0 = chan_theta_mat['hrc_all']\n",
    "hrt0 = chan_theta_mat['hrt_all']\n",
    "GH0 = chan_theta_mat['GH_all']\n",
    "hrcH0 = chan_theta_mat['hrcH_all']\n",
    "hrtH0 = chan_theta_mat['hrtH_all']\n",
    "\n",
    "total_num = G0.shape[2] #\n",
    "\n",
    "G = torch.zeros([total_num,N,M])+1j*torch.zeros([total_num,N,M])\n",
    "hrc = torch.zeros([total_num,N,1])+1j*torch.zeros([total_num,N,1])\n",
    "hrt = torch.zeros([total_num,N,1])+1j*torch.zeros([total_num,N,1])\n",
    "GH = torch.zeros([total_num,M,N])+1j*torch.zeros([total_num,M,N])\n",
    "hrcH = torch.zeros([total_num,1,N])+1j*torch.zeros([total_num,1,N])\n",
    "hrtH = torch.zeros([total_num,1,N])+1j*torch.zeros([total_num,1,N])\n",
    "for i in range(total_num):\n",
    "    G[i,:,:]=torch.from_numpy(G0[:,:,i])\n",
    "    hrc[i,:,:]=torch.from_numpy(hrc0[:,i].reshape(N,1))\n",
    "    hrt[i,:,:]=torch.from_numpy(hrt0[:,i].reshape(N,1))\n",
    "    GH[i,:,:]=torch.from_numpy(GH0[:,:,i])\n",
    "    hrcH[i,:,:]=torch.from_numpy(hrcH0[:,i].reshape(1,N))\n",
    "    hrtH[i,:,:]=torch.from_numpy(hrtH0[:,i].reshape(1,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChannelFile_test = r'Test_Channel_N_32.mat'\n",
    "chan_theta_mat_test = scio.loadmat(ChannelFile_test)\n",
    "\n",
    "G0_test = chan_theta_mat_test['G_all']\n",
    "hrc0_test = chan_theta_mat_test['hrc_all']\n",
    "hrt0_test = chan_theta_mat_test['hrt_all']\n",
    "GH0_test = chan_theta_mat_test['GH_all']\n",
    "hrcH0_test = chan_theta_mat_test['hrcH_all']\n",
    "hrtH0_test = chan_theta_mat_test['hrtH_all']\n",
    "\n",
    "test_num = G0_test.shape[2]\n",
    "\n",
    "G_test = torch.zeros([test_num,N,M])+1j*torch.zeros([test_num,N,M])\n",
    "hrc_test = torch.zeros([test_num,N,1])+1j*torch.zeros([test_num,N,1])\n",
    "hrt_test = torch.zeros([test_num,N,1])+1j*torch.zeros([test_num,N,1])\n",
    "GH_test = torch.zeros([test_num,M,N])+1j*torch.zeros([test_num,M,N])\n",
    "hrcH_test = torch.zeros([test_num,1,N])+1j*torch.zeros([test_num,1,N])\n",
    "hrtH_test = torch.zeros([test_num,1,N])+1j*torch.zeros([test_num,1,N])\n",
    "for i in range(test_num):\n",
    "    G_test[i,:,:]=torch.from_numpy(G0_test[:,:,i])\n",
    "    hrc_test[i,:,:]=torch.from_numpy(hrc0_test[:,i].reshape(N,1))\n",
    "    hrt_test[i,:,:]=torch.from_numpy(hrt0_test[:,i].reshape(N,1))\n",
    "    GH_test[i,:,:]=torch.from_numpy(G0_test[:,:,i].conj().T)\n",
    "    hrcH_test[i,:,:]=torch.from_numpy(hrc0_test[:,i].conj().reshape(1,N))\n",
    "    hrtH_test[i,:,:]=torch.from_numpy(hrt0_test[:,i].conj().reshape(1,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_com = torch.matmul(torch.diag_embed(hrcH.squeeze(),dim1=1),G)\n",
    "psiH_com = torch.matmul(GH,torch.diag_embed(hrc.squeeze(),dim1=1))\n",
    "R_com = torch.matmul(psi_com,psiH_com).reshape(total_num,1,N,N)\n",
    "R_com_sep = torch.cat([torch.real(R_com),torch.imag(R_com)],axis=1)\n",
    "\n",
    "psi_rad = torch.matmul(torch.diag_embed(hrtH.squeeze(),dim1=1),G)\n",
    "psiH_rad = torch.matmul(GH,torch.diag_embed(hrt.squeeze(),dim1=1))\n",
    "R_rad = torch.matmul(psi_rad,psiH_rad).reshape(total_num,1,N,N)\n",
    "R_rad_sep = torch.cat([torch.real(R_rad),torch.imag(R_rad)],axis=1)\n",
    "\n",
    "R_sep = torch.cat([R_rad_sep,R_com_sep],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_sep_mean = torch.mean(R_sep,dim=2).reshape(total_num,4,1,N)\n",
    "R_sep_std = torch.std(R_sep,dim=2).reshape(total_num,4,1,N)\n",
    "R_sep_scaled = (R_sep-R_sep_mean)/R_sep_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrc_vec,hrt_vec,G_vec = hrc.reshape(total_num,-1),hrt.reshape(total_num,-1),G.reshape(total_num,-1)\n",
    "origin_dataset = torch.cat((torch.real(G_vec),torch.imag(G_vec),torch.real(hrt_vec),torch.imag(hrt_vec),torch.real(hrc_vec),torch.imag(hrc_vec)),axis=-1)\n",
    "\n",
    "hrcH_vec,hrtH_vec,GH_vec = hrcH.reshape(total_num,-1),hrtH.reshape(total_num,-1),GH.reshape(total_num,-1)\n",
    "origin_datasetH = torch.cat((torch.real(GH_vec),torch.imag(GH_vec),torch.real(hrtH_vec),torch.imag(hrtH_vec),torch.real(hrcH_vec),torch.imag(hrcH_vec)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_com_test = torch.matmul(torch.diag_embed(hrcH_test.squeeze(),dim1=1),G_test)\n",
    "psiH_com_test = torch.matmul(GH_test,torch.diag_embed(hrc_test.squeeze(),dim1=1))\n",
    "R_com_test = torch.matmul(psi_com_test,psiH_com_test).reshape(test_num,1,N,N)\n",
    "R_com_test_sep = torch.cat([torch.real(R_com_test),torch.imag(R_com_test)],axis=1)\n",
    "\n",
    "psi_rad_test = torch.matmul(torch.diag_embed(hrtH_test.squeeze(),dim1=1),G_test)\n",
    "psiH_rad_test = torch.matmul(GH_test,torch.diag_embed(hrt_test.squeeze(),dim1=1))\n",
    "R_rad_test = torch.matmul(psi_rad_test,psiH_rad_test).reshape(test_num,1,N,N)\n",
    "R_rad_test_sep = torch.cat([torch.real(R_rad_test),torch.imag(R_rad_test)],axis=1)\n",
    "\n",
    "R_test_sep = torch.cat([R_rad_test_sep,R_com_test_sep],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_test_sep_mean = torch.mean(R_test_sep,dim=2).reshape(test_num,4,1,N)\n",
    "R_test_sep_std = torch.std(R_test_sep,dim=2).reshape(test_num,4,1,N)\n",
    "R_test_sep_scaled = (R_test_sep-R_test_sep_mean)/R_test_sep_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrc_test_vec,hrt_test_vec,G_test_vec = hrc_test.reshape(test_num,-1),hrt_test.reshape(test_num,-1),G_test.reshape(test_num,-1)\n",
    "origin_dataset_test = torch.cat((torch.real(G_test_vec),torch.imag(G_test_vec),torch.real(hrt_test_vec),torch.imag(hrt_test_vec),torch.real(hrc_test_vec),torch.imag(hrc_test_vec)),axis=-1)\n",
    "\n",
    "hrcH_test_vec,hrtH_test_vec,GH_test_vec = hrcH_test.reshape(test_num,-1),hrtH_test.reshape(test_num,-1),GH_test.reshape(test_num,-1)\n",
    "origin_datasetH_test = torch.cat((torch.real(GH_test_vec),torch.imag(GH_test_vec),torch.real(hrtH_test_vec),torch.imag(hrtH_test_vec),torch.real(hrcH_test_vec),torch.imag(hrcH_test_vec)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(Dataset):\n",
    "    def __init__(self,R,chans,chans2):\n",
    "        self.data = R.to(torch.float32)\n",
    "        self.label = chans.to(torch.float32)\n",
    "        self.label2 = chans2.to(torch.float32)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index],self.label[index],self.label2[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1000\n",
    "trainloader = DataLoader(dataset=mydata(R_sep_scaled,origin_dataset,origin_datasetH), shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynet(nn.Module):\n",
    "    def __init__(self,M,N):\n",
    "        super().__init__()\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        \n",
    "        def conv_bn(dim_in, dim_out, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(dim_in, dim_out, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(dim_out),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        def conv_dw(dim_in, dim_out, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(dim_in, dim_in, 3, stride, 1, groups=dim_in, bias=False),\n",
    "                nn.BatchNorm2d(dim_in),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(dim_in, dim_out, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(dim_out),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "        \t# input: 4 x 32 x 32\n",
    "            conv_bn(  4,  32, 1), \t# 32 x 32 x 32\n",
    "            conv_dw( 32,  64, 1), \t# 64 x 32 x 32\n",
    "            conv_dw( 64, 128, 2), \t# 128 x 16 x 16                   \n",
    "            conv_dw(128, 256, 2), \t# 256 x 8 x 8                 \n",
    "            conv_dw(256, 512, 2), \t# 512 x 4 x 4           \n",
    "            conv_dw(512, 1024, 2), \t# 1024 x 2 x 2\n",
    "            nn.AvgPool2d(2),\t\t# 1024 x 1 x 1\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, self.N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)  \n",
    "\n",
    "        phase = x.to(torch.complex128)\n",
    "        theta_real = torch.cos(phase)\n",
    "        theta_imag = torch.sin(phase)\n",
    "        theta = theta_real+1j*theta_imag\n",
    "        thetaH = theta_real-1j*theta_imag\n",
    "        \n",
    "        return theta, thetaH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_w(ht,hc,Pt,Tau,sigma):\n",
    "    temp1 = torch.abs(hc.conj().T @ ht)**2\n",
    "    \n",
    "    u1 = hc/torch.linalg.norm(hc)\n",
    "    \n",
    "    u2_ = ht-(u1.conj().T @ ht) * u1\n",
    "    u2 = u2_/torch.linalg.norm(u2_)\n",
    "    \n",
    "    x1_ = u1.conj().T @ ht\n",
    "    x1 = torch.sqrt(Tau*sigma/torch.linalg.norm(hc)**2)*x1_/torch.linalg.norm(x1_)\n",
    "    \n",
    "    x2_ = u2.conj().T @ ht\n",
    "    temp2 = Pt-Tau*sigma/torch.linalg.norm(hc)**2\n",
    "    \n",
    "    if temp2<0:\n",
    "        temp2sqrt = 1j*torch.sqrt(Tau*sigma/torch.linalg.norm(hc)**2-Pt)\n",
    "    else:\n",
    "        temp2sqrt = torch.sqrt(temp2)\n",
    "    \n",
    "    x2 = temp2sqrt*x2_/torch.linalg.norm(x2_)\n",
    "    \n",
    "    if np.sqrt(Pt)*temp1>Tau*sigma*torch.linalg.norm(ht)**2:\n",
    "        w = np.sqrt(Pt)*ht/torch.linalg.norm(ht)\n",
    "    else:\n",
    "        w = x1*u1+x2*u2\n",
    "        if torch.linalg.norm(w)**2>Pt:\n",
    "            w = np.sqrt(Pt)*w/torch.linalg.norm(w)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(chan,chanH,theta,thetaH,M,N):\n",
    "\n",
    "    G0 = chan[:,:2*N*M];    G = G0[:,:N*M]+1j*G0[:,N*M:]\n",
    "    G = G.view([-1,N,M]);   G = G.to(torch.complex128)\n",
    "    \n",
    "    G0H = chanH[:,:2*N*M];    GH = G0H[:,:N*M]+1j*G0H[:,N*M:]\n",
    "    GH = GH.view([-1,M,N]);   GH = GH.to(torch.complex128)\n",
    "    \n",
    "    hrt0 = chan[:,2*N*M:2*(N*M+N)];   hrt = hrt0[:,:N]+1j*hrt0[:,N:]\n",
    "    hrt = hrt.view([-1,N,1]);    hrt = hrt.to(torch.complex128)\n",
    "    \n",
    "    hrt0H = chanH[:,2*N*M:2*(N*M+N)];   hrtH = hrt0H[:,:N]+1j*hrt0H[:,N:]\n",
    "    hrtH = hrtH.view([-1,1,N]);    hrtH = hrtH.to(torch.complex128)\n",
    "\n",
    "    hrc0 = chan[:,2*(N*M+N):];   hrc = hrc0[:,:N]+1j*hrc0[:,N:]\n",
    "    hrc = hrc.view([-1,N,1]);    hrc = hrc.to(torch.complex128)\n",
    "    \n",
    "    hrc0H = chanH[:,2*(N*M+N):];   hrcH = hrc0H[:,:N]+1j*hrc0H[:,N:]\n",
    "    hrcH = hrcH.view([-1,1,N]);    hrcH = hrcH.to(torch.complex128)\n",
    "    \n",
    "    batch_num = G.shape[0]\n",
    "    temp1 = torch.matmul(GH, torch.diag_embed(theta,dim1=1))    \n",
    "    temp2 = torch.matmul(torch.diag_embed(thetaH,dim1=1),G)   \n",
    "    hc = torch.matmul(temp1, hrc)  \n",
    "    ht = torch.matmul(temp1, hrt)\n",
    "    htH = torch.matmul(hrtH,temp2)\n",
    "    Ht = torch.matmul(ht,htH)\n",
    "    \n",
    "    reward_vector = torch.matmul(Ht,hc)\n",
    "  \n",
    "    reward_vector = reward_vector[:,:,0] \n",
    "    reward = torch.linalg.norm(reward_vector,axis=-1) \n",
    "    reward = reward.to(torch.float32)\n",
    "    a = 0.8*torch.linalg.norm(Ht,axis=[1,2])\n",
    "#     print(torch.mean(a))\n",
    "\n",
    "    loss = -torch.mean(reward+a)\n",
    "    return loss, hc, ht, Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.001\n",
    "\n",
    "mymodel = mynet(M,N).to(device)\n",
    "optimizer = optim.Adam(mymodel.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  Train Loss: -0.2358  Test Loss: -0.2525  Train SNRt: 11.3696  Train SNRc: 10.0596  Test SNRt: 11.8214  Test SNRc: 10.0783\n",
      "Epoch 2:  Train Loss: -0.2502  Test Loss: -0.2549  Train SNRt: 11.6543  Train SNRc: 10.3805  Test SNRt: 12.2337  Test SNRc: 10.3340\n",
      "Epoch 3:  Train Loss: -0.2516  Test Loss: -0.2552  Train SNRt: 11.6169  Train SNRc: 10.1872  Test SNRt: 12.2414  Test SNRc: 10.1641\n",
      "Epoch 4:  Train Loss: -0.2523  Test Loss: -0.2565  Train SNRt: 11.9885  Train SNRc: 10.4024  Test SNRt: 12.4151  Test SNRc: 10.3856\n",
      "Epoch 5:  Train Loss: -0.2527  Test Loss: -0.2568  Train SNRt: 12.0162  Train SNRc: 10.3863  Test SNRt: 12.5012  Test SNRc: 10.3529\n",
      "Epoch 6:  Train Loss: -0.2530  Test Loss: -0.2570  Train SNRt: 12.0454  Train SNRc: 10.4128  Test SNRt: 12.5559  Test SNRc: 10.3568\n",
      "Epoch 7:  Train Loss: -0.2533  Test Loss: -0.2569  Train SNRt: 12.0786  Train SNRc: 10.3022  Test SNRt: 12.6431  Test SNRc: 10.1642\n",
      "Epoch 8:  Train Loss: -0.2535  Test Loss: -0.2573  Train SNRt: 12.3019  Train SNRc: 10.4411  Test SNRt: 12.6802  Test SNRc: 10.3804\n",
      "Epoch 9:  Train Loss: -0.2537  Test Loss: -0.2578  Train SNRt: 12.3741  Train SNRc: 10.4107  Test SNRt: 12.8062  Test SNRc: 10.1938\n",
      "Epoch 10:  Train Loss: -0.2539  Test Loss: -0.2575  Train SNRt: 12.3772  Train SNRc: 10.2832  Test SNRt: 12.7822  Test SNRc: 10.1946\n",
      "Epoch 11:  Train Loss: -0.2541  Test Loss: -0.2579  Train SNRt: 12.4022  Train SNRc: 10.4217  Test SNRt: 12.9159  Test SNRc: 10.1393\n",
      "Epoch 12:  Train Loss: -0.2543  Test Loss: -0.2576  Train SNRt: 12.5027  Train SNRc: 10.3273  Test SNRt: 12.9533  Test SNRc: 10.3665\n",
      "Epoch 13:  Train Loss: -0.2544  Test Loss: -0.2580  Train SNRt: 12.5278  Train SNRc: 10.3799  Test SNRt: 13.0211  Test SNRc: 10.6446\n",
      "Epoch 14:  Train Loss: -0.2545  Test Loss: -0.2580  Train SNRt: 12.6071  Train SNRc: 10.5219  Test SNRt: 13.0586  Test SNRc: 10.2752\n",
      "Epoch 15:  Train Loss: -0.2546  Test Loss: -0.2582  Train SNRt: 12.7283  Train SNRc: 10.3428  Test SNRt: 13.0741  Test SNRc: 10.6264\n",
      "Epoch 16:  Train Loss: -0.2547  Test Loss: -0.2585  Train SNRt: 12.7945  Train SNRc: 10.2819  Test SNRt: 13.1204  Test SNRc: 10.4906\n",
      "Epoch 17:  Train Loss: -0.2548  Test Loss: -0.2583  Train SNRt: 12.7600  Train SNRc: 10.2775  Test SNRt: 13.0934  Test SNRc: 10.6811\n",
      "Epoch 18:  Train Loss: -0.2549  Test Loss: -0.2580  Train SNRt: 12.7471  Train SNRc: 10.2470  Test SNRt: 13.1941  Test SNRc: 10.5687\n",
      "Epoch 19:  Train Loss: -0.2550  Test Loss: -0.2586  Train SNRt: 12.9425  Train SNRc: 10.2498  Test SNRt: 13.2478  Test SNRc: 10.3234\n",
      "Epoch 20:  Train Loss: -0.2550  Test Loss: -0.2586  Train SNRt: 12.8719  Train SNRc: 10.2617  Test SNRt: 13.1253  Test SNRc: 10.5191\n",
      "Epoch 21:  Train Loss: -0.2551  Test Loss: -0.2586  Train SNRt: 12.9059  Train SNRc: 10.3216  Test SNRt: 13.2805  Test SNRc: 10.6280\n",
      "Epoch 22:  Train Loss: -0.2552  Test Loss: -0.2586  Train SNRt: 12.9137  Train SNRc: 10.3483  Test SNRt: 13.2653  Test SNRc: 10.4930\n",
      "Epoch 23:  Train Loss: -0.2553  Test Loss: -0.2588  Train SNRt: 12.9628  Train SNRc: 10.3240  Test SNRt: 13.2211  Test SNRc: 10.4566\n",
      "Epoch 24:  Train Loss: -0.2553  Test Loss: -0.2586  Train SNRt: 12.9817  Train SNRc: 10.3168  Test SNRt: 13.2826  Test SNRc: 10.3521\n",
      "Epoch 25:  Train Loss: -0.2554  Test Loss: -0.2587  Train SNRt: 12.9938  Train SNRc: 10.4481  Test SNRt: 13.2629  Test SNRc: 10.4562\n",
      "Epoch 26:  Train Loss: -0.2554  Test Loss: -0.2590  Train SNRt: 13.0494  Train SNRc: 10.3298  Test SNRt: 13.3673  Test SNRc: 10.3358\n",
      "Epoch 27:  Train Loss: -0.2555  Test Loss: -0.2590  Train SNRt: 13.0494  Train SNRc: 10.4158  Test SNRt: 13.3681  Test SNRc: 10.4370\n",
      "Epoch 28:  Train Loss: -0.2555  Test Loss: -0.2588  Train SNRt: 12.9759  Train SNRc: 10.2370  Test SNRt: 13.3631  Test SNRc: 10.4786\n",
      "Epoch 29:  Train Loss: -0.2556  Test Loss: -0.2589  Train SNRt: 13.0967  Train SNRc: 10.3128  Test SNRt: 13.3562  Test SNRc: 10.3145\n",
      "Epoch 30:  Train Loss: -0.2556  Test Loss: -0.2587  Train SNRt: 13.0625  Train SNRc: 10.3327  Test SNRt: 13.2834  Test SNRc: 10.4779\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "ppp = 200\n",
    "losses = []\n",
    "losses_test = []\n",
    "SNRc_test_all = []\n",
    "SNRt_test_all = []\n"
    "mymodel.train()\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i,(data,label,labelH) in enumerate(trainloader):\n",
    "        input_R = data.to(device)\n",
    "        theta_pred,thetaH_pred = mymodel(input_R)\n",
    "        \n",
    "        y_chan = label.to(device)\n",
    "        yH_chan = labelH.to(device)\n",
    "        loss, _, _, _ = cal_loss(y_chan,yH_chan,theta_pred,thetaH_pred,M,N)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        mymodel.eval()\n",
    "        \n",
    "        ### Train ###\n",
    "        input_R_train = R_sep_scaled[0:ppp].to(device)\n",
    "        theta_pred_train,thetaH_pred_train = mymodel(input_R_train)\n",
    "        \n",
    "        y_chan_train = origin_dataset[0:ppp].to(device)\n",
    "        yH_chan_train = origin_datasetH[0:ppp].to(device)\n",
    "        _, hc_train2, ht_train2, Ht_train2 = cal_loss(y_chan_train,yH_chan_train,theta_pred_train,thetaH_pred_train,M,N)\n",
    "        \n",
    "        SNRc_train = torch.zeros((ppp,1))\n",
    "        SNRt_train = torch.zeros((ppp,1))\n",
    "        for i in range(ppp):\n",
    "            ht_train_temp = ht_train2[i,:,:]\n",
    "            Ht_train_temp = Ht_train2[i,:,:]\n",
    "            hc_train_temp = hc_train2[i,:,:]\n",
    "            w_train2 = generate_w(ht_train_temp,hc_train_temp,P,Tau,sigma2)\n",
    "            SNRc_train[i,:] = torch.abs(w_train2.T.conj() @ hc_train_temp)**2/sigma2\n",
    "            SNRt_train[i,:] = torch.linalg.norm(Ht_train_temp @ w_train2)**2/sigma2\n",
    "        \n",
    "        ### Test ###\n",
    "        input_R_test = R_test_sep_scaled.to(device)\n",
    "        theta_pred_test,thetaH_pred_test = mymodel(input_R_test)\n",
    "        \n",
    "        y_chan_test = origin_dataset_test.to(device)\n",
    "        yH_chan_test = origin_datasetH_test.to(device)\n",
    "        loss_test, hc_test2, ht_test2, Ht_test2 = cal_loss(y_chan_test,yH_chan_test,theta_pred_test,thetaH_pred_test,M,N)\n",
    "        \n",
    "        SNRc_test = torch.zeros((test_num,1))\n",
    "        SNRt_test = torch.zeros((test_num,1))\n",
    "        for i in range(test_num):\n",
    "            ht_test_temp = ht_test2[i,:,:]\n",
    "            Ht_test_temp = Ht_test2[i,:,:]\n",
    "            hc_test_temp = hc_test2[i,:,:]\n",
    "            w_test2 = generate_w(ht_test_temp,hc_test_temp,P,Tau,sigma2)\n",
    "            SNRc_test[i,:] = torch.abs(w_test2.T.conj() @ hc_test_temp)**2/sigma2\n",
    "            SNRt_test[i,:] = torch.linalg.norm(Ht_test_temp @ w_test2)**2/sigma2\n",
    "        \n",
    "        losses_test.append(loss_test)\n",
    "        SNRt_test_all.append(torch.mean(SNRt_test))\n",
    "        SNRc_test_all.append(torch.mean(SNRc_test))\n",
    "        \n",
    "        mymodel.train()\n",
    "        losses.append(running_loss / len(trainloader))\n",
    "        print('Epoch {}:  Train Loss: {:.4f}  Test Loss: {:.4f}  Train SNRt: {:.4f}  Train SNRc: {:.4f}  Test SNRt: {:.4f}  Test SNRc: {:.4f}'.format(\n",
    "            e + 1,\n",
    "            running_loss / len(trainloader),\n",
    "            loss_test,\n",
    "            torch.mean(SNRt_train),\n",
    "            torch.mean(SNRc_train),\n",
    "            torch.mean(SNRt_test),\n",
    "            torch.mean(SNRc_test)\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
